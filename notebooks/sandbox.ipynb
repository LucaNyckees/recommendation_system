{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "ROOT = os.getenv(\"ROOT\")\n",
    "sys.path.append(ROOT)\n",
    "\n",
    "from src.nlp.regressor import BertRegressorPipeline\n",
    "from src.data_loader import load_reviews\n",
    "from src.processing import reviews_processing\n",
    "from src.nlp.classifier import BERTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_reviews(category=\"All_beauty\", frac=0.001)\n",
    "df = reviews_processing(df=df, clean_text=False)\n",
    "sub = df.rename(columns={\"rating\": \"target\", \"review_input\": \"text\"})[[\"target\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pipeline = BertRegressorPipeline(df=sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">]</span><span style=\"color: #000080; text-decoration-color: #000080\"> | INFO</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  | split : </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">{</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">'train_set': </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">421</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">, 'eval_set': </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">141</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">, 'test_set': </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">}</span>                  <a href=\"file:///Users/lucanyckees/Desktop/my-repos/recommendation_system/src/nlp/regressor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">regressor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/lucanyckees/Desktop/my-repos/recommendation_system/src/nlp/regressor.py#116\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;92m[\u001b[0m\u001b[1;36m16\u001b[0m\u001b[92m:\u001b[0m\u001b[1;36m04\u001b[0m\u001b[92m:\u001b[0m\u001b[1;36m03\u001b[0m\u001b[1;92m]\u001b[0m\u001b[34m | INFO\u001b[0m\u001b[37m  | split : \u001b[0m\u001b[1;37m{\u001b[0m\u001b[37m'train_set': \u001b[0m\u001b[1;36m421\u001b[0m\u001b[37m, 'eval_set': \u001b[0m\u001b[1;36m141\u001b[0m\u001b[37m, 'test_set': \u001b[0m\u001b[1;36m140\u001b[0m\u001b[1;37m}\u001b[0m                  \u001b]8;id=50631;file:///Users/lucanyckees/Desktop/my-repos/recommendation_system/src/nlp/regressor.py\u001b\\\u001b[2mregressor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=75954;file:///Users/lucanyckees/Desktop/my-repos/recommendation_system/src/nlp/regressor.py#116\u001b\\\u001b[2m116\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_pipeline._prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertRegressor were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['cls_layer1.bias', 'cls_layer1.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'ff1.bias', 'ff1.weight', 'ff2.bias', 'ff2.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_pipeline._setup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]Python(95864) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/lucanyckees/Desktop/my-repos/recommendation_system/venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch:   0%|          | 0/2 [03:45<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lucanyckees/Desktop/my-repos/recommendation_system/notebooks/sandbox.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lucanyckees/Desktop/my-repos/recommendation_system/notebooks/sandbox.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m bert_pipeline\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Desktop/my-repos/recommendation_system/src/nlp/regressor.py:195\u001b[0m, in \u001b[0;36mBertRegressorPipeline.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(output, target\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mtype_as(output))\n\u001b[1;32m    194\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m--> 195\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    197\u001b[0m     train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    199\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining loss is \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/my-repos/recommendation_system/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    485\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/my-repos/recommendation_system/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m\"\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Desktop/my-repos/recommendation_system/venv/lib/python3.11/site-packages/torch/optim/adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    214\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    216\u001b[0m     has_complex \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    217\u001b[0m         group,\n\u001b[1;32m    218\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m         state_steps,\n\u001b[1;32m    224\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     adam(\n\u001b[1;32m    227\u001b[0m         params_with_grad,\n\u001b[1;32m    228\u001b[0m         grads,\n\u001b[1;32m    229\u001b[0m         exp_avgs,\n\u001b[1;32m    230\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    231\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    232\u001b[0m         state_steps,\n\u001b[1;32m    233\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    234\u001b[0m         has_complex\u001b[39m=\u001b[39;49mhas_complex,\n\u001b[1;32m    235\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    236\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    237\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    238\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    239\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    240\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    242\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    243\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    246\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    247\u001b[0m     )\n\u001b[1;32m    249\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Desktop/my-repos/recommendation_system/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m disabled_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    160\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/my-repos/recommendation_system/venv/lib/python3.11/site-packages/torch/optim/adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 766\u001b[0m func(\n\u001b[1;32m    767\u001b[0m     params,\n\u001b[1;32m    768\u001b[0m     grads,\n\u001b[1;32m    769\u001b[0m     exp_avgs,\n\u001b[1;32m    770\u001b[0m     exp_avg_sqs,\n\u001b[1;32m    771\u001b[0m     max_exp_avg_sqs,\n\u001b[1;32m    772\u001b[0m     state_steps,\n\u001b[1;32m    773\u001b[0m     amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    774\u001b[0m     has_complex\u001b[39m=\u001b[39;49mhas_complex,\n\u001b[1;32m    775\u001b[0m     beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    776\u001b[0m     beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    777\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    778\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    779\u001b[0m     eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    780\u001b[0m     maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    781\u001b[0m     capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    782\u001b[0m     differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    783\u001b[0m     grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    784\u001b[0m     found_inf\u001b[39m=\u001b[39;49mfound_inf,\n\u001b[1;32m    785\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/my-repos/recommendation_system/venv/lib/python3.11/site-packages/torch/optim/adam.py:431\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    429\u001b[0m         denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    430\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m         denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    433\u001b[0m     param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n\u001b[1;32m    435\u001b[0m \u001b[39m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bert_pipeline.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(95056) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/lucanyckees/Desktop/my-repos/recommendation_system/venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/lucanyckees/Desktop/my-repos/recommendation_system/venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([11])) that is different to the input size (torch.Size([11, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_pipeline.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(95203) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], device='mps:0') tensor([1., 4., 5., 5., 5., 5., 5., 5., 5., 5., 2., 2., 3., 4., 5., 5.],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "predicted_label = []\n",
    "actual_label = []\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, target in bert_pipeline.validation_loader:\n",
    "        input_ids, attention_mask, target = (\n",
    "            input_ids.to(device),\n",
    "            attention_mask.to(device),\n",
    "            target.to(device),\n",
    "        )\n",
    "        output = bert_pipeline.model(input_ids, attention_mask)\n",
    "\n",
    "        predicted_label += output\n",
    "        actual_label += target\n",
    "        print(output, target)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(3., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(2., device='mps:0'),\n",
       " tensor(4., device='mps:0'),\n",
       " tensor(1., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(5., device='mps:0'),\n",
       " tensor(1., device='mps:0')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
